{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a515d2c3",
   "metadata": {},
   "source": [
    "# websearch agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61e49c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pocketflow import Node,Flow\n",
    "import yaml\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc1f1e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_llm(prompt):\n",
    "    client = OpenAI(\n",
    "        base_url= os.getenv(\"BASE_URL\"),\n",
    "        api_key=os.getenv(\"DASHSCOPE_API_KEY\")\n",
    "    )\n",
    "    res = client.chat.completions.create(\n",
    "        model = os.getenv(\"MODEL_NAME\"),\n",
    "        messages = [{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }]\n",
    "    )\n",
    "    return res.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4aaac662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 决定节点：作用是判断问题是直接返回回答还是继续search\n",
    "\n",
    "class DecideAction(Node):\n",
    "    def prep(self, shared):\n",
    "        context = shared.get(\"context\",\"没有之前的搜索\")\n",
    "        question = shared['question']\n",
    "\n",
    "        return question, context\n",
    "    \n",
    "    def exec(self, prep_res):\n",
    "        question, context = prep_res\n",
    "        print(\"Agent 正在决定下一步步骤...\")\n",
    "        prompt = f\"\"\"\n",
    "            ### 背景信息\n",
    "            你是一名可以进行网络搜索的研究助手。\n",
    "            问题：{question}\n",
    "            以往研究：{context}\n",
    "            ### 行动范围\n",
    "            [1] search\n",
    "            描述：在网络上查找更多信息\n",
    "            参数：query（字符串）：要搜索的内容\n",
    "\n",
    "            [2] answer\n",
    "            描述：用现有知识回答问题\n",
    "            参数：answer（字符串）：问题的最终答案\n",
    "            \n",
    "            ### 下一步行动\n",
    "            根据背景信息和可用行动，决定下一步行动。\n",
    "            请按以下格式返回你的回应：\n",
    "\n",
    "            ```yaml\n",
    "            thinking: |\n",
    "                <你的分步推理过程>\n",
    "            action: search 或 answer\n",
    "            reason: <你选择该行动的原因>\n",
    "            answer: <如果行动是answer，填写此处>\n",
    "            search_query: <如果行动是search，填写具体的搜索查询>\n",
    "            ```\n",
    "            \n",
    "            ###重要提示：请务必做到：\n",
    "            所有多行字段使用适当的缩进（4 个空格）\n",
    "            多行文本字段使用 | 字符\n",
    "            单行字段不使用 | 字符\n",
    "            \"\"\"\n",
    "\n",
    "        res = call_llm(prompt)\n",
    "        yaml_str = res.split(\"```yaml\")[1].split(\"```\")[0].strip()\n",
    "\n",
    "        return yaml.safe_load(yaml_str)\n",
    "\n",
    "    def post(self, shared, prep_res, exec_res):\n",
    "        if exec_res['action'] == 'search':\n",
    "            shared['search_query'] = exec_res['search_query']\n",
    "            print(f\"Agent 决定去搜索：{shared['search_query']}\")\n",
    "        else:\n",
    "            shared['context'] = exec_res['answer']\n",
    "            print(\"Agent 决定回答答案\")\n",
    "\n",
    "        return exec_res['action']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dd31968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 进行知识搜索--应该通过搜索引擎，这里直接返回进行演示\n",
    "def search_engine(query: str):\n",
    "    res = \"\"\"\n",
    "        LlamaFirewall是Meta开发的LLM安全防护框架，其中包括了四个组件构成四道防线，但是在实际使用中可根据需要使用其中一个或多个组件：\n",
    "        1）\tPromptGuard 是框架的第一道防线，基于轻量级 BERT 分类器专注于快速识别直接的提示注入攻击。它以超低延迟处理用户输入和不可信数据，特别擅长捕捉经典的越狱模式和社会工程学攻击，为高吞吐量环境提供了理想的安全保障\n",
    "        2）\tAlignmentCheck 作为框架的深度监控层，通过实时审计 LLM 代理的推理过程，利用少样本提示和语义分析技术检测目标劫持和间接提示注入。它能够确保 AI 系统的决策始终与用户意图保持一致，即使是面对不透明或黑盒模型也能有效工作。\n",
    "        3）\tRegex + Custom Scanners 提供了灵活的自定义安全规则层，通过配置正则表达式和简单 LLM 提示来识别已知攻击模式和不良行为。这个组件支持跨语言检测，使组织能够快速应对新出现的威胁。\n",
    "        4）\tCodeShield 作为专用的代码安全守护者，对 LLM 生成的代码进行实时静态分析，支持 Semgrep 和正则规则，覆盖八种编程语言。它能有效防止不安全代码被执行或部署，为代码生成应用提供了必要的安全保障。\n",
    "        \"\"\"\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a261a429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search节点：作用是搜索答案\n",
    "class SearchWeb(Node):\n",
    "    def prep(self, shared):\n",
    "        return shared['search_query']\n",
    "    \n",
    "\n",
    "    def exec(self, prep_res):\n",
    "        print(f\"Agent 正在从网络搜索：{prep_res}\")\n",
    "        res = search_engine(prep_res)\n",
    "\n",
    "        return res\n",
    "    \n",
    "\n",
    "    def post(self, shared, prep_res, exec_res):\n",
    "        previous = shared.get(\"context\", \"\")\n",
    "        shared[\"context\"] = previous + \"\\n\\nSEARCH:\" + shared['search_query'] + \"\\nRESULT:\" + exec_res\n",
    "        print(\"Agent 搜索到数据，正在分析...\")\n",
    "        \n",
    "        return 'decide'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f5bc3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 回答问题节点\n",
    "class AnswerQuestion(Node):\n",
    "    def prep(self, shared):\n",
    "        return shared['question'], shared.get(\"context\", \"\")\n",
    "    \n",
    "    def exec(self, prep_res):\n",
    "        question, context = prep_res\n",
    "        print(\"Agent 正在回答问题...\")\n",
    "        prompt = f\"\"\"\n",
    "            ## 背景信息\n",
    "            根据以下信息，回答问题。\n",
    "            问题：{question}\n",
    "            研究资料：{context}\n",
    "            \n",
    "            ## 你的回答：\n",
    "            利用研究结果提供全面的答案。\n",
    "            \"\"\"\n",
    "        \n",
    "        answer = call_llm(prompt=prompt)\n",
    "        return answer\n",
    "\n",
    "    \n",
    "    def post(self, shared, prep_res, exec_res):\n",
    "        shared['answer'] = exec_res\n",
    "        \n",
    "        return 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a0e9037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_travel_agent_flow():\n",
    "    decide_node = DecideAction()\n",
    "    search_node = SearchWeb()\n",
    "    answer_node = AnswerQuestion()\n",
    "\n",
    "    # 表示当 decide_node 节点的决策结果为 \"search\" 时，工作流将跳转到 search_node 节点继续执行\n",
    "    decide_node  - \"search\" >> search_node  \n",
    "\n",
    "    # 表示当 decide_node 节点的决策结果为 \"answer\" 时，工作流将跳转到 answer_node 节点继续执行\n",
    "    decide_node  - \"answer\" >> answer_node\n",
    "    \n",
    "    # 表示当 search_node 节点执行完毕后，返回 \"decide\" 信号，工作流将回到 decide_node 节点重新进行决策\n",
    "    search_node  - \"decide\" >> decide_node\n",
    "\n",
    "    return Flow(start=decide_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a437ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent 正在决定下一步步骤...\n",
      "Agent 决定去搜索：LlamaFirewall components\n",
      "Agent 正在从网络搜索：LlamaFirewall components\n",
      "Agent 搜索到数据，正在分析...\n",
      "Agent 正在决定下一步步骤...\n",
      "Agent 决定回答答案\n",
      "Agent 正在回答问题...\n",
      "LlamaFirewall 是由 Meta 开发的针对大语言模型（LLM）的安全防护框架，其包含以下四个主要组件：\n",
      "\n",
      "1. **PromptGuard**：用于快速识别提示注入攻击，保护模型免受恶意输入的影响。  \n",
      "2. **AlignmentCheck**：用于实时审计模型的推理过程，确保其行为符合预期的安全和伦理标准。  \n",
      "3. **Regex + Custom Scanners**：提供灵活的自定义安全规则，允许用户根据特定需求配置安全策略。  \n",
      "4. **CodeShield**：用于对模型生成的代码进行实时安全分析，防止潜在的代码级威胁。\n",
      "\n",
      "这些组件既可以单独使用，也可以组合集成，以应对不同应用场景下的安全威胁。\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    shared = {\n",
    "        \"question\": \"LlamaFirewall有哪些组件？\"\n",
    "    }\n",
    "    travel_agent_flow = create_travel_agent_flow()\n",
    "    travel_agent_flow.run(shared)\n",
    "    print (shared.get(\"answer\", \"俺不知道耶～😅\"))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pocket-flow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
